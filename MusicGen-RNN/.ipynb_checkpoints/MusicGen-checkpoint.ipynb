{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Music Generation using LSTMs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pEI6gbW9Xh2t"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dropout, TimeDistributed, Dense, Activation, Embedding\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.utils import *\n",
    "from music21 import *\n",
    "from IPython.display import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "99F2Mtptj4MS"
   },
   "outputs": [],
   "source": [
    "data_file = \"Data_Tunes.txt\"\n",
    "charIndex_json = \"char_to_index.json\"\n",
    "BATCH_SIZE = 32\n",
    "SEQ_LENGTH = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_XacfcrSX3OK"
   },
   "source": [
    "ABC Notation\n",
    "\n",
    "ABC notation of Music\n",
    "There are two parts in ABC-notation.\n",
    "\n",
    "Part-1 represents meta data. Lines in the Part-1 of the tune notation, beginning with a letter followed by a colon, indicate various aspects of the tune such as the index, when there are more than one tune in a file (X:), the title (T:), the time signature (M:), the default note length (L:), the type of tune (R:) and the key (K:).\n",
    "\n",
    "Part-2 represents the tune, which is a sequence of characters where each character represents some musical note."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kU9kGmh6RKyI"
   },
   "outputs": [],
   "source": [
    "# Function to remove Part-1 of  and append a start token i.e 'Z' for each tune in the dataset\n",
    "\n",
    "def preprocess(data):\n",
    "  list1=list(data)\n",
    "  list2=['\\n','\\n','\\n']\n",
    "  ignore=['X','T','M','S','K','P']\n",
    "  i=0\n",
    "  #to remove Part1:\n",
    "  while(i<len(list1)):\n",
    "    if(((list1[i] in ignore) and (list1[i+1]==\":\"))or list1[i]=='%' ):\n",
    "      del list2[-1]\n",
    "      while(list1[i]!='\\n'):\n",
    "        i=i+1\n",
    "    list2.append(list1[i])\n",
    "    i=i+1\n",
    "  i=0\n",
    "  #to append 'Z'(start token)\n",
    "  preprocess_data=[]\n",
    "  while(i<len(list2)):\n",
    "    if(list2[i]=='\\n'and list2[i+1]=='\\n' and list2[i+2]=='\\n'):\n",
    "      preprocess_data.append('Z')\n",
    "      i=i+3\n",
    "    else:\n",
    "      preprocess_data.append(list2[i])\n",
    "      i=i+1\n",
    "  return preprocess_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MYOozwWeDhTv"
   },
   "outputs": [],
   "source": [
    "# Function to create char_to_index and index_to_char dictionaries so as to map each character to an index and vice versa.\n",
    "# Returns all_characters_as_indices i.e an array containing all characters of the dataset replaced with their corresponding indices as per the vocabulary.\n",
    "# Also returns num_unique_chars i.e an integer equal to number of unique characters in the data.\n",
    "\n",
    "def read_data(preprocess_data):\n",
    "  char_to_index = {ch: i for (i, ch) in enumerate(sorted(list(set(preprocess_data))))}\n",
    "\n",
    "    \n",
    "  with open(charIndex_json, mode = \"w\") as f:\n",
    "        json.dump(char_to_index, f)\n",
    "        \n",
    "  index_to_char = {i: ch for (ch, i) in char_to_index.items()}\n",
    "  num_unique_chars = len(char_to_index)\n",
    "  all_characters_as_indices = np.asarray([char_to_index[c] for c in preprocess_data], dtype = np.int32)\n",
    "  return all_characters_as_indices,num_unique_chars\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4FWErp9l_c1y"
   },
   "outputs": [],
   "source": [
    "# Function which returns X and Y which will be used as input and target output for training the model.\n",
    "\n",
    "def input_output(all_chars_as_indices,num_unique_chars):\n",
    "    total_length = all_chars_as_indices.shape[0]\n",
    "    num_examples=int(total_length/SEQ_LENGTH)\n",
    "    X=np.zeros((num_examples,SEQ_LENGTH))\n",
    "    Y=np.zeros((num_examples,SEQ_LENGTH,num_unique_chars))\n",
    "    for i in range(num_examples):\n",
    "      for j in range(SEQ_LENGTH):\n",
    "        X[i,j]=all_chars_as_indices[i*SEQ_LENGTH+j]\n",
    "        Y[i,j,all_chars_as_indices[i*SEQ_LENGTH+j+1]]=1\n",
    "    return X,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0H5nVWJv_ihC"
   },
   "outputs": [],
   "source": [
    "# Function to build the training model\n",
    "\n",
    "def build_model( seq_length, num_unique_chars):\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Embedding(input_dim = num_unique_chars, output_dim = 512, input_shape = (seq_length,))) \n",
    "    \n",
    "    model.add(LSTM(256, return_sequences = True))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(LSTM(256, return_sequences = True))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LSTM(256, return_sequences = True))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    \n",
    "    model.add(TimeDistributed(Dense(num_unique_chars)))\n",
    "\n",
    "    model.add(Activation(\"softmax\"))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "hDNI8EFAwran",
    "outputId": "d706902f-7bcc-4add-dbe8-f00338ecf25f"
   },
   "outputs": [],
   "source": [
    "# Image(filename='./drive/My Drive/build.png') #image of training model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2bF_Z6KIbqw2"
   },
   "source": [
    "stateful:\n",
    "\n",
    " If True, the last state for each sample at index i in a batch will be used as initial state for the sample of index i in the following batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eGgrLrX4BnHh"
   },
   "outputs": [],
   "source": [
    "#Function which builds model for generating music sequences.\n",
    "\n",
    "def make_model(num_unique_chars):\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Embedding(input_dim = num_unique_chars, output_dim = 512, batch_input_shape = (1, 1))) \n",
    "  \n",
    "# stateful: If True, the last state for each sample at index i in a batch will be used \n",
    "# as initial state for the sample of index i in the following batch.\n",
    "    model.add(LSTM(256, return_sequences = True, stateful = True))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(LSTM(256, return_sequences = True, stateful = True))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(LSTM(256,return_sequences=True, stateful = True)) \n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add((Dense(num_unique_chars)))\n",
    "    model.add(Activation(\"softmax\"))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "O6VNDGiQw5KY",
    "outputId": "90706643-8f6a-414b-f7a5-fdf55cbf3bef"
   },
   "outputs": [],
   "source": [
    "# Image(filename='./drive/My Drive/generate.png') #image showing music generation model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iw446L1OBzzl"
   },
   "outputs": [],
   "source": [
    "# Function which generates music sequences of length=gen_seq_length.\n",
    "def generate_sequence(gen_seq_length):\n",
    "    with open(charIndex_json) as f:\n",
    "        char_to_index = json.load(f)\n",
    "    index_to_char = {i:ch for ch, i in char_to_index.items()}\n",
    "    num_unique_chars = len(index_to_char)\n",
    "    \n",
    "    model = make_model(num_unique_chars)\n",
    "    model.load_weights(\"./weights/weights.80.hdf5\")\n",
    "     \n",
    "    sequence_index = [char_to_index['Z']]\n",
    "\n",
    "    for _ in range(gen_seq_length):\n",
    "        batch = np.zeros((1, 1))\n",
    "        batch[0, 0] = sequence_index[-1]\n",
    "        \n",
    "        predicted_probs = model.predict_on_batch(batch).ravel()\n",
    "        sample = np.random.choice(range(num_unique_chars), size = 1, p = predicted_probs)\n",
    "        \n",
    "        \n",
    "        sequence_index.append(sample[0])\n",
    "    \n",
    "        \n",
    "    \n",
    "    seq = ''.join(index_to_char[c] for c in sequence_index)\n",
    "    seq='M:6/8\\n'+str(seq)\n",
    "    return seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kveYEr8HCtcZ"
   },
   "outputs": [],
   "source": [
    "# function to create a midi file given a music sequence in abc notation.\n",
    "def convert_to_midi(abc):\n",
    "    c = converter.subConverters.ConverterABC()\n",
    "    c.registerOutputExtensions = (\"midi\")\n",
    "    c.parseData(abc)\n",
    "    s = c.stream\n",
    "    s.write('midi', fp='demos1.mid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "yI3ceWwF_XL6",
    "outputId": "e2d1a356-5176-4b18-93d0-266a742127c8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of preprocess_data-116963\n",
      "vocab_size=59\n",
      "all_characters=[33 44 57 ... 15 20 57]\n",
      "length of all_characters-116963\n",
      "shape of X=(913, 128)\n",
      "shape of Y=(913, 128, 59)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "file = open(data_file, mode = 'r')\n",
    "data = file.read()\n",
    "file.close()\n",
    "preprocess_data=preprocess(data)\n",
    "all_characters_as_indices,num_unique_chars=read_data(preprocess_data)\n",
    "X,Y=input_output(all_characters_as_indices,num_unique_chars)\n",
    "print(\"length of preprocess_data-{}\".format(len(preprocess_data)))\n",
    "print(\"vocab_size={}\".format(num_unique_chars))\n",
    "print(\"all_characters={}\".format(all_characters_as_indices))\n",
    "print(\"length of all_characters-{}\".format(len(all_characters_as_indices)))\n",
    "print(\"shape of X={}\".format(X.shape))\n",
    "print(\"shape of Y={}\".format(Y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "_TNCaeqyAda9",
    "outputId": "174462fc-4e1d-424c-c0b6-a743cdfc7bcf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 128, 512)          30208     \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 128, 256)          787456    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 128, 256)          0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 128, 256)          525312    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128, 256)          0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 128, 256)          525312    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128, 256)          0         \n",
      "_________________________________________________________________\n",
      "time_distributed (TimeDistri (None, 128, 59)           15163     \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 128, 59)           0         \n",
      "=================================================================\n",
      "Total params: 1,883,451\n",
      "Trainable params: 1,883,451\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model=build_model(SEQ_LENGTH,num_unique_chars)\n",
    "model.summary()\n",
    "model.compile(loss = \"categorical_crossentropy\", optimizer = \"adam\", metrics = [\"accuracy\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n"
     ]
    },
    {
     "ename": "UnknownError",
     "evalue": " [_Derived_]  Fail to find the dnn implementation.\n\t [[{{node CudnnRNN}}]]\n\t [[sequential/lstm/StatefulPartitionedCall]] [Op:__inference_train_function_8576]\n\nFunction call stack:\ntrain_function -> train_function -> train_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-49da56962e90>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mcheckpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModelCheckpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'./weights/weights.{epoch:02d}.hdf5'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msave_best_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msave_weights_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msave_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m80\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    846\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m    847\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 848\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    849\u001b[0m               \u001b[0;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m               \u001b[0;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    609\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 611\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    612\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2418\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2419\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2420\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2422\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1663\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1664\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1665\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1666\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1667\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1746\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    599\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnknownError\u001b[0m:  [_Derived_]  Fail to find the dnn implementation.\n\t [[{{node CudnnRNN}}]]\n\t [[sequential/lstm/StatefulPartitionedCall]] [Op:__inference_train_function_8576]\n\nFunction call stack:\ntrain_function -> train_function -> train_function\n"
     ]
    }
   ],
   "source": [
    "checkpoint=ModelCheckpoint(filepath='./weights/weights.{epoch:02d}.hdf5',monitor='loss',save_best_only=True,save_weights_only=True,save_freq=1)\n",
    "model.fit(X,Y,batch_size=BATCH_SIZE,epochs=80,callbacks=[checkpoint])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "iWz5iH8oj3yf",
    "outputId": "bbd5e890-72b4-443d-f5f5-81a6324acc99"
   },
   "outputs": [],
   "source": [
    "music = generate_sequence(192)\n",
    "print(\"\\nMUSIC SEQUENCE GENERATED: \\n{}\".format(music))\n",
    "convert_to_midi(music)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ybSsFZd6xU6f"
   },
   "source": [
    "We have finished training and generating music sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "MusGenfinal.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
