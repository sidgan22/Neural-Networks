{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Music Generation using LSTMs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pEI6gbW9Xh2t"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dropout, TimeDistributed, Dense, Activation, Embedding\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.utils import *\n",
    "from music21 import *\n",
    "from IPython.display import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "99F2Mtptj4MS"
   },
   "outputs": [],
   "source": [
    "data_file = \"Data_Tunes.txt\"\n",
    "charIndex_json = \"char_to_index.json\"\n",
    "BATCH_SIZE = 16\n",
    "SEQ_LENGTH = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_XacfcrSX3OK"
   },
   "source": [
    "ABC Notation\n",
    "\n",
    "ABC notation of Music\n",
    "There are two parts in ABC-notation.\n",
    "\n",
    "Part-1 represents meta data. Lines in the Part-1 of the tune notation, beginning with a letter followed by a colon, indicate various aspects of the tune such as the index, when there are more than one tune in a file (X:), the title (T:), the time signature (M:), the default note length (L:), the type of tune (R:) and the key (K:).\n",
    "\n",
    "Part-2 represents the tune, which is a sequence of characters where each character represents some musical note."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kU9kGmh6RKyI"
   },
   "outputs": [],
   "source": [
    "# Function to remove Part-1 of  and append a start token i.e 'Z' for each tune in the dataset\n",
    "\n",
    "def preprocess(data):\n",
    "  list1=list(data)\n",
    "  list2=['\\n','\\n','\\n']\n",
    "  ignore=['X','T','M','S','K','P']\n",
    "  i=0\n",
    "  #to remove Part1:\n",
    "  while(i<len(list1)):\n",
    "    if(((list1[i] in ignore) and (list1[i+1]==\":\"))or list1[i]=='%' ):\n",
    "      del list2[-1]\n",
    "      while(list1[i]!='\\n'):\n",
    "        i=i+1\n",
    "    list2.append(list1[i])\n",
    "    i=i+1\n",
    "  i=0\n",
    "  #to append 'Z'(start token)\n",
    "  preprocess_data=[]\n",
    "  while(i<len(list2)):\n",
    "    if(list2[i]=='\\n'and list2[i+1]=='\\n' and list2[i+2]=='\\n'):\n",
    "      preprocess_data.append('Z')\n",
    "      i=i+3\n",
    "    else:\n",
    "      preprocess_data.append(list2[i])\n",
    "      i=i+1\n",
    "  return preprocess_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MYOozwWeDhTv"
   },
   "outputs": [],
   "source": [
    "# Function to create char_to_index and index_to_char dictionaries so as to map each character to an index and vice versa.\n",
    "# Returns all_characters_as_indices i.e an array containing all characters of the dataset replaced with their corresponding indices as per the vocabulary.\n",
    "# Also returns num_unique_chars i.e an integer equal to number of unique characters in the data.\n",
    "\n",
    "def read_data(preprocess_data):\n",
    "  char_to_index = {ch: i for (i, ch) in enumerate(sorted(list(set(preprocess_data))))}\n",
    "\n",
    "    \n",
    "  with open(charIndex_json, mode = \"w\") as f:\n",
    "        json.dump(char_to_index, f)\n",
    "        \n",
    "  index_to_char = {i: ch for (ch, i) in char_to_index.items()}\n",
    "  num_unique_chars = len(char_to_index)\n",
    "  all_characters_as_indices = np.asarray([char_to_index[c] for c in preprocess_data], dtype = np.int32)\n",
    "  return all_characters_as_indices,num_unique_chars\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4FWErp9l_c1y"
   },
   "outputs": [],
   "source": [
    "# Function which returns X and Y which will be used as input and target output for training the model.\n",
    "\n",
    "def input_output(all_chars_as_indices,num_unique_chars):\n",
    "    total_length = all_chars_as_indices.shape[0]\n",
    "    num_examples=int(total_length/SEQ_LENGTH)\n",
    "    X=np.zeros((num_examples,SEQ_LENGTH))\n",
    "    Y=np.zeros((num_examples,SEQ_LENGTH,num_unique_chars))\n",
    "    for i in range(num_examples):\n",
    "      for j in range(SEQ_LENGTH):\n",
    "        X[i,j]=all_chars_as_indices[i*SEQ_LENGTH+j]\n",
    "        Y[i,j,all_chars_as_indices[i*SEQ_LENGTH+j+1]]=1\n",
    "    return X,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0H5nVWJv_ihC"
   },
   "outputs": [],
   "source": [
    "# Function to build the training model\n",
    "\n",
    "def build_model( seq_length, num_unique_chars):\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Embedding(input_dim = num_unique_chars, output_dim = 512, input_shape = (seq_length,))) \n",
    "    \n",
    "    model.add(LSTM(256, return_sequences = True))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(LSTM(256, return_sequences = True))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LSTM(256, return_sequences = True))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    \n",
    "    model.add(TimeDistributed(Dense(num_unique_chars)))\n",
    "\n",
    "    model.add(Activation(\"softmax\"))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "hDNI8EFAwran",
    "outputId": "d706902f-7bcc-4add-dbe8-f00338ecf25f"
   },
   "outputs": [],
   "source": [
    "# Image(filename='./drive/My Drive/build.png') #image of training model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2bF_Z6KIbqw2"
   },
   "source": [
    "stateful:\n",
    "\n",
    " If True, the last state for each sample at index i in a batch will be used as initial state for the sample of index i in the following batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eGgrLrX4BnHh"
   },
   "outputs": [],
   "source": [
    "#Function which builds model for generating music sequences.\n",
    "\n",
    "def make_model(num_unique_chars):\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Embedding(input_dim = num_unique_chars, output_dim = 512, batch_input_shape = (1, 1))) \n",
    "  \n",
    "# stateful: If True, the last state for each sample at index i in a batch will be used \n",
    "# as initial state for the sample of index i in the following batch.\n",
    "    model.add(LSTM(256, return_sequences = True, stateful = True))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(LSTM(256, return_sequences = True, stateful = True))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(LSTM(256,return_sequences=True, stateful = True)) \n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add((Dense(num_unique_chars)))\n",
    "    model.add(Activation(\"softmax\"))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "O6VNDGiQw5KY",
    "outputId": "90706643-8f6a-414b-f7a5-fdf55cbf3bef"
   },
   "outputs": [],
   "source": [
    "# Image(filename='./drive/My Drive/generate.png') #image showing music generation model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iw446L1OBzzl"
   },
   "outputs": [],
   "source": [
    "# Function which generates music sequences of length=gen_seq_length.\n",
    "def generate_sequence(gen_seq_length):\n",
    "    with open(charIndex_json) as f:\n",
    "        char_to_index = json.load(f)\n",
    "    index_to_char = {i:ch for ch, i in char_to_index.items()}\n",
    "    num_unique_chars = len(index_to_char)\n",
    "    \n",
    "    model = make_model(num_unique_chars)\n",
    "    model.load_weights(\"./weights/weights.79.hdf5\")\n",
    "     \n",
    "    sequence_index = [char_to_index['Z']]\n",
    "\n",
    "    for _ in range(gen_seq_length):\n",
    "        batch = np.zeros((1, 1))\n",
    "        batch[0, 0] = sequence_index[-1]\n",
    "        \n",
    "        predicted_probs = model.predict_on_batch(batch).ravel()\n",
    "        sample = np.random.choice(range(num_unique_chars), size = 1, p = predicted_probs)\n",
    "        \n",
    "        \n",
    "        sequence_index.append(sample[0])\n",
    "    \n",
    "        \n",
    "    \n",
    "    seq = ''.join(index_to_char[c] for c in sequence_index)\n",
    "    seq='M:6/8\\n'+str(seq)\n",
    "    return seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kveYEr8HCtcZ"
   },
   "outputs": [],
   "source": [
    "# function to create a midi file given a music sequence in abc notation.\n",
    "def convert_to_midi(abc):\n",
    "    c = converter.subConverters.ConverterABC()\n",
    "    c.registerOutputExtensions = (\"midi\")\n",
    "    c.parseData(abc)\n",
    "    s = c.stream\n",
    "    s.write('midi', fp='demos1.mid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "yI3ceWwF_XL6",
    "outputId": "e2d1a356-5176-4b18-93d0-266a742127c8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of preprocess_data-116963\n",
      "vocab_size=59\n",
      "all_characters=[33 44 57 ... 15 20 57]\n",
      "length of all_characters-116963\n",
      "shape of X=(913, 128)\n",
      "shape of Y=(913, 128, 59)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "file = open(data_file, mode = 'r')\n",
    "data = file.read()\n",
    "file.close()\n",
    "preprocess_data=preprocess(data)\n",
    "all_characters_as_indices,num_unique_chars=read_data(preprocess_data)\n",
    "X,Y=input_output(all_characters_as_indices,num_unique_chars)\n",
    "print(\"length of preprocess_data-{}\".format(len(preprocess_data)))\n",
    "print(\"vocab_size={}\".format(num_unique_chars))\n",
    "print(\"all_characters={}\".format(all_characters_as_indices))\n",
    "print(\"length of all_characters-{}\".format(len(all_characters_as_indices)))\n",
    "print(\"shape of X={}\".format(X.shape))\n",
    "print(\"shape of Y={}\".format(Y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "_TNCaeqyAda9",
    "outputId": "174462fc-4e1d-424c-c0b6-a743cdfc7bcf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 128, 512)          30208     \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 128, 256)          787456    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 128, 256)          0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 128, 256)          525312    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128, 256)          0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 128, 256)          525312    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128, 256)          0         \n",
      "_________________________________________________________________\n",
      "time_distributed (TimeDistri (None, 128, 59)           15163     \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 128, 59)           0         \n",
      "=================================================================\n",
      "Total params: 1,883,451\n",
      "Trainable params: 1,883,451\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model=build_model(SEQ_LENGTH,num_unique_chars)\n",
    "model.summary()\n",
    "model.compile(loss = \"categorical_crossentropy\", optimizer = \"adam\", metrics = [\"accuracy\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/80\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fd9300f7d40> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fd9300f7d40> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "58/58 [==============================] - 3s 47ms/step - loss: 3.1574 - accuracy: 0.1778\n",
      "Epoch 2/80\n",
      "58/58 [==============================] - 3s 47ms/step - loss: 2.8242 - accuracy: 0.2370\n",
      "Epoch 3/80\n",
      "58/58 [==============================] - 3s 50ms/step - loss: 2.2861 - accuracy: 0.3629\n",
      "Epoch 4/80\n",
      "58/58 [==============================] - 3s 47ms/step - loss: 1.9217 - accuracy: 0.4292\n",
      "Epoch 5/80\n",
      "58/58 [==============================] - 3s 47ms/step - loss: 1.7433 - accuracy: 0.4595\n",
      "Epoch 6/80\n",
      "58/58 [==============================] - 3s 47ms/step - loss: 1.6370 - accuracy: 0.4783\n",
      "Epoch 7/80\n",
      "58/58 [==============================] - 3s 47ms/step - loss: 1.5685 - accuracy: 0.4928\n",
      "Epoch 8/80\n",
      "58/58 [==============================] - 3s 47ms/step - loss: 1.5092 - accuracy: 0.5100\n",
      "Epoch 9/80\n",
      "58/58 [==============================] - 3s 47ms/step - loss: 1.4558 - accuracy: 0.5255\n",
      "Epoch 10/80\n",
      "58/58 [==============================] - 3s 46ms/step - loss: 1.4064 - accuracy: 0.5400\n",
      "Epoch 11/80\n",
      "58/58 [==============================] - 3s 47ms/step - loss: 1.3658 - accuracy: 0.5515\n",
      "Epoch 12/80\n",
      "58/58 [==============================] - 3s 48ms/step - loss: 1.3255 - accuracy: 0.5627\n",
      "Epoch 13/80\n",
      "58/58 [==============================] - 3s 49ms/step - loss: 1.2920 - accuracy: 0.5753\n",
      "Epoch 14/80\n",
      "58/58 [==============================] - 3s 48ms/step - loss: 1.2566 - accuracy: 0.5866\n",
      "Epoch 15/80\n",
      "58/58 [==============================] - 3s 49ms/step - loss: 1.2249 - accuracy: 0.5968\n",
      "Epoch 16/80\n",
      "58/58 [==============================] - 3s 48ms/step - loss: 1.2006 - accuracy: 0.6054\n",
      "Epoch 17/80\n",
      "58/58 [==============================] - 3s 50ms/step - loss: 1.1683 - accuracy: 0.6152\n",
      "Epoch 18/80\n",
      "58/58 [==============================] - 3s 50ms/step - loss: 1.1480 - accuracy: 0.6219\n",
      "Epoch 19/80\n",
      "58/58 [==============================] - 3s 50ms/step - loss: 1.1201 - accuracy: 0.6297\n",
      "Epoch 20/80\n",
      "58/58 [==============================] - 3s 51ms/step - loss: 1.0910 - accuracy: 0.6404\n",
      "Epoch 21/80\n",
      "58/58 [==============================] - 3s 52ms/step - loss: 1.0741 - accuracy: 0.6460\n",
      "Epoch 22/80\n",
      "58/58 [==============================] - 3s 53ms/step - loss: 1.0490 - accuracy: 0.6526\n",
      "Epoch 23/80\n",
      "58/58 [==============================] - 3s 53ms/step - loss: 1.0240 - accuracy: 0.6636\n",
      "Epoch 24/80\n",
      "58/58 [==============================] - 3s 53ms/step - loss: 1.0071 - accuracy: 0.6683\n",
      "Epoch 25/80\n",
      "58/58 [==============================] - 3s 54ms/step - loss: 0.9846 - accuracy: 0.6747\n",
      "Epoch 26/80\n",
      "58/58 [==============================] - 3s 54ms/step - loss: 0.9657 - accuracy: 0.6803\n",
      "Epoch 27/80\n",
      "58/58 [==============================] - 3s 54ms/step - loss: 0.9515 - accuracy: 0.6844\n",
      "Epoch 28/80\n",
      "58/58 [==============================] - 3s 55ms/step - loss: 0.9235 - accuracy: 0.6939\n",
      "Epoch 29/80\n",
      "58/58 [==============================] - 3s 56ms/step - loss: 0.8985 - accuracy: 0.7032\n",
      "Epoch 30/80\n",
      "58/58 [==============================] - 3s 55ms/step - loss: 0.8839 - accuracy: 0.7077\n",
      "Epoch 31/80\n",
      "58/58 [==============================] - 3s 56ms/step - loss: 0.8603 - accuracy: 0.7155\n",
      "Epoch 32/80\n",
      "58/58 [==============================] - 3s 58ms/step - loss: 0.8404 - accuracy: 0.7200\n",
      "Epoch 33/80\n",
      "58/58 [==============================] - 3s 57ms/step - loss: 0.8273 - accuracy: 0.7268\n",
      "Epoch 34/80\n",
      "58/58 [==============================] - 3s 57ms/step - loss: 0.8149 - accuracy: 0.7294\n",
      "Epoch 35/80\n",
      "58/58 [==============================] - 3s 58ms/step - loss: 0.7977 - accuracy: 0.7357\n",
      "Epoch 36/80\n",
      "58/58 [==============================] - 3s 60ms/step - loss: 0.7687 - accuracy: 0.7454\n",
      "Epoch 37/80\n",
      "58/58 [==============================] - 3s 59ms/step - loss: 0.7504 - accuracy: 0.7523\n",
      "Epoch 38/80\n",
      "58/58 [==============================] - 3s 59ms/step - loss: 0.7302 - accuracy: 0.7597\n",
      "Epoch 39/80\n",
      "58/58 [==============================] - 3s 59ms/step - loss: 0.7119 - accuracy: 0.7642\n",
      "Epoch 40/80\n",
      "58/58 [==============================] - 3s 59ms/step - loss: 0.6959 - accuracy: 0.7695\n",
      "Epoch 41/80\n",
      "58/58 [==============================] - 3s 60ms/step - loss: 0.6748 - accuracy: 0.7759\n",
      "Epoch 42/80\n",
      "58/58 [==============================] - 3s 60ms/step - loss: 0.6612 - accuracy: 0.7798\n",
      "Epoch 43/80\n",
      "58/58 [==============================] - 3s 60ms/step - loss: 0.6402 - accuracy: 0.7871\n",
      "Epoch 44/80\n",
      "58/58 [==============================] - 3s 59ms/step - loss: 0.6249 - accuracy: 0.7938\n",
      "Epoch 45/80\n",
      "58/58 [==============================] - 4s 61ms/step - loss: 0.6119 - accuracy: 0.7980\n",
      "Epoch 46/80\n",
      "58/58 [==============================] - 3s 60ms/step - loss: 0.5919 - accuracy: 0.8037\n",
      "Epoch 47/80\n",
      "58/58 [==============================] - 3s 60ms/step - loss: 0.5811 - accuracy: 0.8072\n",
      "Epoch 48/80\n",
      "58/58 [==============================] - 4s 60ms/step - loss: 0.5687 - accuracy: 0.8116\n",
      "Epoch 49/80\n",
      "58/58 [==============================] - 4s 60ms/step - loss: 0.5486 - accuracy: 0.8188\n",
      "Epoch 50/80\n",
      "58/58 [==============================] - 3s 60ms/step - loss: 0.5361 - accuracy: 0.8210\n",
      "Epoch 51/80\n",
      "58/58 [==============================] - 3s 60ms/step - loss: 0.5293 - accuracy: 0.8235\n",
      "Epoch 52/80\n",
      "58/58 [==============================] - 4s 61ms/step - loss: 0.5271 - accuracy: 0.8243\n",
      "Epoch 53/80\n",
      "58/58 [==============================] - 3s 60ms/step - loss: 0.5069 - accuracy: 0.8302\n",
      "Epoch 54/80\n",
      "58/58 [==============================] - 4s 62ms/step - loss: 0.4927 - accuracy: 0.8362\n",
      "Epoch 55/80\n",
      "58/58 [==============================] - 4s 62ms/step - loss: 0.4807 - accuracy: 0.8394\n",
      "Epoch 56/80\n",
      "58/58 [==============================] - 4s 61ms/step - loss: 0.4569 - accuracy: 0.8476\n",
      "Epoch 57/80\n",
      "58/58 [==============================] - 4s 63ms/step - loss: 0.4437 - accuracy: 0.8525\n",
      "Epoch 58/80\n",
      "58/58 [==============================] - 3s 60ms/step - loss: 0.4497 - accuracy: 0.8484\n",
      "Epoch 59/80\n",
      "58/58 [==============================] - 4s 63ms/step - loss: 0.4351 - accuracy: 0.8542\n",
      "Epoch 60/80\n",
      "58/58 [==============================] - 4s 64ms/step - loss: 0.4171 - accuracy: 0.8613\n",
      "Epoch 61/80\n",
      "58/58 [==============================] - 4s 63ms/step - loss: 0.4062 - accuracy: 0.8637\n",
      "Epoch 62/80\n",
      "58/58 [==============================] - 4s 62ms/step - loss: 0.4064 - accuracy: 0.8642\n",
      "Epoch 63/80\n",
      "58/58 [==============================] - 4s 62ms/step - loss: 0.3933 - accuracy: 0.8672\n",
      "Epoch 64/80\n",
      "58/58 [==============================] - 4s 63ms/step - loss: 0.3849 - accuracy: 0.8714\n",
      "Epoch 65/80\n",
      "58/58 [==============================] - 4s 63ms/step - loss: 0.3806 - accuracy: 0.8727\n",
      "Epoch 66/80\n",
      "58/58 [==============================] - 4s 64ms/step - loss: 0.3804 - accuracy: 0.8713\n",
      "Epoch 67/80\n",
      "58/58 [==============================] - 4s 61ms/step - loss: 0.3704 - accuracy: 0.8747\n",
      "Epoch 68/80\n",
      "58/58 [==============================] - 4s 63ms/step - loss: 0.3518 - accuracy: 0.8816\n",
      "Epoch 69/80\n",
      "58/58 [==============================] - 4s 63ms/step - loss: 0.3471 - accuracy: 0.8824\n",
      "Epoch 70/80\n",
      "58/58 [==============================] - 4s 64ms/step - loss: 0.3417 - accuracy: 0.8846\n",
      "Epoch 71/80\n",
      "58/58 [==============================] - 4s 63ms/step - loss: 0.3292 - accuracy: 0.8883\n",
      "Epoch 72/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58/58 [==============================] - 4s 62ms/step - loss: 0.3211 - accuracy: 0.8909\n",
      "Epoch 73/80\n",
      "58/58 [==============================] - 4s 63ms/step - loss: 0.3252 - accuracy: 0.8906\n",
      "Epoch 74/80\n",
      "58/58 [==============================] - 4s 67ms/step - loss: 0.3199 - accuracy: 0.8915\n",
      "Epoch 75/80\n",
      "58/58 [==============================] - 4s 65ms/step - loss: 0.3206 - accuracy: 0.8915\n",
      "Epoch 76/80\n",
      "58/58 [==============================] - 4s 63ms/step - loss: 0.2982 - accuracy: 0.8998\n",
      "Epoch 77/80\n",
      "58/58 [==============================] - 4s 63ms/step - loss: 0.2939 - accuracy: 0.8999\n",
      "Epoch 78/80\n",
      "58/58 [==============================] - 4s 63ms/step - loss: 0.2857 - accuracy: 0.9040\n",
      "Epoch 79/80\n",
      "58/58 [==============================] - 4s 61ms/step - loss: 0.2891 - accuracy: 0.9017\n",
      "Epoch 80/80\n",
      "58/58 [==============================] - 4s 62ms/step - loss: 0.2855 - accuracy: 0.9029\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fd9300b5bd0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint=ModelCheckpoint(filepath='./weights/weights.{epoch:02d}.hdf5',monitor='loss',save_best_only=True,save_weights_only=True,period=1)\n",
    "model.fit(X,Y,batch_size=BATCH_SIZE,epochs=80,callbacks=[checkpoint])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "iWz5iH8oj3yf",
    "outputId": "bbd5e890-72b4-443d-f5f5-81a6324acc99"
   },
   "outputs": [],
   "source": [
    "music = generate_sequence(192)\n",
    "print(\"\\nMUSIC SEQUENCE GENERATED: \\n{}\".format(music))\n",
    "convert_to_midi(music)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ybSsFZd6xU6f"
   },
   "source": [
    "We have finished training and generating music sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Save the TF Lite model.\n",
    "with tf.io.gfile.GFile('model.tflite', 'wb') as f:\n",
    "  f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "MusGenfinal.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
